{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "397f3f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pprint\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b127cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"datasets\"\n",
    "tfrecords_dir = \"tfrecords\"\n",
    "train_images_dir = os.path.join(root_dir, \"train2017\")\n",
    "val_images_dir = os.path.join(root_dir, \"val2017\")\n",
    "train_annotation_file = os.path.join(root_dir, \"lvis_v1_train.json\")\n",
    "val_annotation_file = os.path.join(root_dir, \"lvis_v1_val.json\")\n",
    "\n",
    "train_images_url = \"http://images.cocodataset.org/zips/train2017.zip\"\n",
    "val_images_url = \"http://images.cocodataset.org/zips/val2017.zip\"\n",
    "train_annotations_url = (\n",
    "    \"https://s3-us-west-2.amazonaws.com/dl.fbaipublicfiles.com/LVIS/lvis_v1_train.json.zip\"\n",
    ")\n",
    "val_annotations_url = (\n",
    "    \"https://s3-us-west-2.amazonaws.com/dl.fbaipublicfiles.com/LVIS/lvis_v1_val.json.zip\"\n",
    ")\n",
    "coco_annotations_url = (\"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e3b1917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download image files\n",
    "if not os.path.exists(train_images_dir):\n",
    "    image_zip = tf.keras.utils.get_file(\n",
    "        \"images.zip\", cache_dir=os.path.abspath(\".\"), origin=train_images_url, extract=True,\n",
    "    )\n",
    "    os.remove(image_zip)\n",
    "if not os.path.exists(val_images_dir):\n",
    "    image_zip = tf.keras.utils.get_file(\n",
    "        \"images.zip\", cache_dir=os.path.abspath(\".\"), origin=val_images_url, extract=True,\n",
    "    )\n",
    "    os.remove(image_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e75d2ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LVIS dataset has been downloaded and extracted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Download caption annotation files\n",
    "if not os.path.exists(train_annotation_file):\n",
    "    annotation_zip = tf.keras.utils.get_file(\n",
    "        \"captions.zip\",\n",
    "        cache_dir=os.path.abspath(\".\"),\n",
    "        origin=train_annotations_url,\n",
    "        extract=True,\n",
    "    )\n",
    "    os.remove(annotation_zip)\n",
    "    \n",
    "if not os.path.exists(val_annotation_file):\n",
    "    annotation_zip = tf.keras.utils.get_file(\n",
    "        \"captions.zip\",\n",
    "        cache_dir=os.path.abspath(\".\"),\n",
    "        origin=val_annotations_url,\n",
    "        extract=True,\n",
    "    )\n",
    "    os.remove(annotation_zip)\n",
    "\n",
    "print(\"The LVIS dataset has been downloaded and extracted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef6f1a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train images: 1270141\n",
      "Number of validation images: 244707\n"
     ]
    }
   ],
   "source": [
    "with open(train_annotation_file, \"r\") as f:\n",
    "    train_annotations = json.load(f)[\"annotations\"]\n",
    "    \n",
    "with open(val_annotation_file, \"r\") as f:\n",
    "    val_annotations = json.load(f)[\"annotations\"] \n",
    "\n",
    "print(f\"Number of train images: {len(train_annotations)}\")\n",
    "print(f\"Number of validation images: {len(val_annotations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28285b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'area': 15.25,\n",
      " 'bbox': [235.4, 291.18, 22.18, 1.65],\n",
      " 'category_id': 1037,\n",
      " 'id': 61,\n",
      " 'image_id': 402711,\n",
      " 'segmentation': [[236.27,\n",
      "                   291.27,\n",
      "                   235.4,\n",
      "                   291.73,\n",
      "                   244.38,\n",
      "                   292.65,\n",
      "                   245.66,\n",
      "                   292.28,\n",
      "                   245.48,\n",
      "                   291.54,\n",
      "                   239.06,\n",
      "                   291.18,\n",
      "                   237.23,\n",
      "                   291.18,\n",
      "                   236.27,\n",
      "                   291.27],\n",
      "                  [251.35,\n",
      "                   291.91,\n",
      "                   251.71,\n",
      "                   292.83,\n",
      "                   257.03,\n",
      "                   292.65,\n",
      "                   257.58,\n",
      "                   291.91,\n",
      "                   256.48,\n",
      "                   291.54,\n",
      "                   255.38,\n",
      "                   291.54,\n",
      "                   251.35,\n",
      "                   291.91]]}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(train_annotations[60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d6a3f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num_samples = 1270141\n",
    "val_num_samples = 244707\n",
    "\n",
    "if not os.path.exists(tfrecords_dir):\n",
    "    os.makedirs(tfrecords_dir)  # creating TFRecords output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12b8b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
    "\n",
    "\n",
    "def float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "def create_example(image, classes_text, bbox):\n",
    "    x, y, w, h = bbox\n",
    "    xmin = x - (w/2.)\n",
    "    ymin = y - (h/2.)\n",
    "    xmax = x + (w/2.)\n",
    "    ymax = y + (h/2.)\n",
    "    feature = {\n",
    "        \"image/encoded\": image_feature(image),\n",
    "        \"image/object/bbox/xmin\": float_feature(xmin),\n",
    "        \"image/object/bbox/ymin\": float_feature(ymin),\n",
    "        \"image/object/bbox/xmax\": float_feature(xmax),\n",
    "        \"image/object/bbox/ymax\": float_feature(ymax),\n",
    "        \"image/object/class/text\": bytes_feature(classes_text),\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f1f9437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since LVIS val instance includes train data, create val first\n",
    "from collections import defaultdict\n",
    "samples = defaultdict(list)\n",
    "for annots in val_annotations:\n",
    "    samples[annots[\"image_id\"]].append(annots)\n",
    "\n",
    "\n",
    "# print(len(samples))\n",
    "\n",
    "with tf.io.TFRecordWriter(tfrecords_dir + \"/LVIS_val.tfrecord\") as writer:\n",
    "    for img_id, sample in samples.items():\n",
    "        bbox = [[] for _ in range(4)]\n",
    "        classes_text = []\n",
    "        for instance in instances:\n",
    "            x, y, w, h = instance[\"bbox\"]\n",
    "            bbox[0].append(x)\n",
    "            bbox[1].append(y)\n",
    "            bbox[2].append(w)\n",
    "            bbox[3].append(h)\n",
    "            classes_text.append(str(instance[\"category_id\"]).encode('utf8'))\n",
    "        image_path = f\"{train_images_dir}/{img_id:012d}.jpg\"\n",
    "        if not os.path.exists(image_path):\n",
    "            image_path = f\"{val_images_dir}/{img_id:012d}.jpg\"\n",
    "        image = open(image_path, 'rb').read()\n",
    "        example = create_example(image, classes_text, np.array(bbox))\n",
    "        writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00500ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# no need val image data anymore\n",
    "import shutil\n",
    "\n",
    "if os.path.exists(train_images_dir):\n",
    "    shutil.rmtree(train_images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60207b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train tfrecord file\n",
    "\n",
    "samples = defaultdict(list)\n",
    "for annots in train_annotations:\n",
    "    samples[annots[\"image_id\"]].append(annots)\n",
    "\n",
    "with tf.io.TFRecordWriter(tfrecords_dir + \"/LVIS_train.tfrecord\") as writer:\n",
    "    for img_id, sample in samples.items():\n",
    "        bbox = [[] for _ in range(4)]\n",
    "        classes_text = []\n",
    "        for instance in instances:\n",
    "            x, y, w, h = instance[\"bbox\"]\n",
    "            bbox[0].append(x)\n",
    "            bbox[1].append(y)\n",
    "            bbox[2].append(w)\n",
    "            bbox[3].append(h)\n",
    "            classes_text.append(str(instance[\"category_id\"]).encode('utf8'))\n",
    "        image_path = f\"{train_images_dir}/{img_id:012d}.jpg\"\n",
    "        image = open(image_path, 'rb').read()\n",
    "        example = create_example(image, classes_text, np.array(bbox))\n",
    "        writer.write(example.SerializeToString())    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
